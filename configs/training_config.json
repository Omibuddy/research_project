{
    "seq_len": 7,
    "num_features": 13,
    "hidden_dim": 512,
    "num_transformer_layers": 4,
    "num_heads": 8,
    "dropout": 0.2,
    "learning_rate": 0.001,
    "weight_decay": 0.01,
    "grad_clip": 1.0,
    "epochs": 100,
    "batch_size": 32,
    "quantiles": [
        0.1,
        0.5,
        0.9
    ],
    "learnable_pe": true,
    "attention_l1_reg_weight": 0.01
}